# Wine Quality Classification: Red & White Wines

> **Overview:** This project demonstrates a machine learning pipeline for classifying wine quality using a publicly available wine dataset. It is intended for **practice and skill demonstration purposes**, showcasing techniques in data preprocessing, model building, evaluation, and visualization.

> **Disclaimer:** This dataset is for practice and has limitations. Models are suitable for internal analytics and process optimization but do **not** meet competitive thresholds for mission-critical automation or direct consumer decision-making without additional safeguards.
---

# Table of Contents
    1. Key Features
                1.1 Data preprocessing
                1.2 Models implemented 
                1.3 Evaluation metrics

    2. Project Structure / File Navigation

    3. Setup & Requirements
                3.1 Python version
                3.2 Required libraries/packages
                3.3 Optional: environment setup instructions

    4. How to Run / Explore
                4.1 Steps to execute the notebook
                4.2 How to regenerate visualizations
                4.3 How to modify or test models

    5. Models & Insights
                Description of each model’s performance
                Confusion matrices, ROC curves, feature importance
                Observations about medium-quality wine, alcohol content, etc.

    6. References + Acknowledgements
---
## 1. Key Features
- **1.1 Data Preprocessing:**  
  - Combined red and white wines for consistent binning of quality labels  
  - Train/test split to prevent data leakage  
  - Feature scaling where necessary  

- **1.2 Models Implemented:**  
  - Logistic Regression (with class weighting)  
  - k-Nearest Neighbors (k-NN)  
  - Decision Tree (with hyperparameter tuning and class weighting)  

- **1.3 Evaluation Metrics:**  
  - Accuracy, Precision, Recall, F1-Score  
  - Confusion Matrices  
  - ROC Curves & AUC  
  - 5-fold Cross-Validation  
  - Statistical significance testing (95% confidence intervals)  
  ---

## 2. Project Structure / File Navigation
- `Wine_Classification.ipynb` → Complete ML pipeline code  
- `Visual_Summary.jpg` → Quick visual summary of insights and key results  
- `Full_Analysis.pdf` → Detailed analysis: heatmaps, ROC curves, AUC, confusion matrices, and feature importance  
- `README.md` → This file  

---
## 3. Setup & Requirements
- Python 3.10+  
- Libraries:
  ```bash
  pandas
  numpy
  matplotlib
  seaborn
  scikit-learn

---

## 4. How to Run / Explore

1. **Open the Notebook**  
   Open `Wine_Classification.ipynb` in your preferred environment: VS Code, Jupyter Notebook, or Google Colab.

2. **Run the Pipeline**  
   Execute the notebook cells sequentially to:
   - Preprocess and clean the data  
   - Train and tune models (Logistic Regression, k-NN, Decision Tree)  
   - Evaluate model performance with accuracy, precision, recall, and F1-Score  

3. **Generate Visuals**  
   The following plots can be regenerated by running the relevant cells:
   - **Confusion Matrices** – visualize classification errors for Red and White wines  
   - **ROC Curves & AUC** – evaluate model discrimination ability  
   - **Feature Importance Plots** – identify the key predictors of wine quality  

4. **Optional Custom Exploration**  
   - Adjust model hyperparameters and re-run training cells  
   - Filter or subset the dataset to test specific scenarios  
   - Compare cross-validation results or generate alternative visualizations

---

## 5. Models & Insights

### Model Performance- Overview
- **Decision Trees** achieved the highest F1-Score for both Red (0.6466) and White wines (0.6169).  
- **k-NN** performed competitively, especially for medium-quality wines, but was slightly less robust overall.  
- **Medium-quality wines** were hardest to classify, with lower precision and recall across models.  
- **Alcohol content** is the most important predictor of wine quality, aligning with consumer perception.  

### Detailed Observations
**Red Wine:**
- **Logistic Regression:** F1-Score 0.5635, confusion matrix indicates misclassification primarily between medium and high quality.  
- **k-NN:** F1-Score 0.6061, better at medium-quality wines.  
- **Decision Tree:** F1-Score 0.6466, highest overall accuracy and balanced prediction.  

**White Wine:**
- **Logistic Regression:** F1-Score 0.5117, struggled with medium-quality wines.  
- **k-NN:** F1-Score 0.5937, moderate improvement in medium-quality classification.  
- **Decision Tree:** F1-Score 0.6169, most balanced performance across classes.  

**Cross-validation & AUC:**
- 5-fold CV confirmed model stability on training data.  
- ROC-AUC indicated that high- and low-quality wines are easier to distinguish than medium-quality wines.  

---

## 6.References + Acknowledgements:
> I would like to thank Prof. Xiaofeng Zhou, and Prof. Indrayani Mishra for guidance and feedback throughout this project. 
This work references concepts from *Data Mining: Concepts and Techniques (4th edition)* by Jiawei Han, Jian Pei, and Hanghang Tong (Morgan Kaufmann).  
The dataset used in this project is the publicly available Wine Quality dataset from the UCI Machine Learning Repository.

